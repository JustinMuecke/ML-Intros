{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own Data Object\n",
    "\n",
    " - make a graph out of the corpus \n",
    " - node: word \n",
    " - feature: embedding\n",
    " - label: POS\n",
    " - edge: between node that neighbour each other in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example corpus\n",
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the corpus\n",
    "tokens = [[word.lower() for word in document.split(\" \")] for document in corpus]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec = Word2Vec(sentences=tokens, vector_size=9, window=2, min_count=1, sg=1)\n",
    "w2v_embedding = word2vec.wv\n",
    "\n",
    "# Create word-to-index mapping\n",
    "word_to_idx = {word: idx for idx, word in enumerate(w2v_embedding.index_to_key)}\n",
    "\n",
    "# Prepare node embeddings\n",
    "embeddings = [w2v_embedding[word].tolist() for word in word_to_idx]\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0,\n",
       " 'the': 1,\n",
       " 'is': 2,\n",
       " 'this': 3,\n",
       " 'first': 4,\n",
       " 'one': 5,\n",
       " 'third': 6,\n",
       " 'and': 7,\n",
       " 'second': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0060,  0.0026,  0.0567,  0.1001, -0.1034, -0.0791,  0.0718,  0.0997,\n",
       "         -0.0557],\n",
       "        [-0.0418,  0.0820, -0.0170, -0.0504,  0.0728, -0.0540, -0.0202,  0.0320,\n",
       "          0.0110],\n",
       "        [-0.0921, -0.1050,  0.0812,  0.0563,  0.0751,  0.0085,  0.0706, -0.0378,\n",
       "         -0.0105],\n",
       "        [ 0.0641, -0.0836, -0.0437, -0.0835, -0.0103,  0.1060, -0.0813, -0.0259,\n",
       "         -0.0215],\n",
       "        [ 0.0897, -0.0659,  0.0005, -0.0528, -0.1067,  0.0556, -0.0973, -0.0488,\n",
       "         -0.0004],\n",
       "        [-0.0033, -0.0851,  0.1068,  0.0554,  0.1026, -0.0906,  0.0500, -0.0460,\n",
       "          0.0092],\n",
       "        [ 0.0944, -0.0496,  0.0502, -0.0754, -0.0394,  0.1044, -0.0175,  0.0036,\n",
       "         -0.0460],\n",
       "        [-0.0854, -0.0168,  0.0274, -0.0099,  0.0615, -0.0305,  0.0251,  0.0606,\n",
       "          0.0927],\n",
       "        [-0.0162, -0.1023,  0.0486,  0.0064,  0.0827, -0.0090, -0.0293, -0.0973,\n",
       "         -0.0095]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare edge indices based on the corpus\n",
    "edges = [[], []]\n",
    "for doc in tokens:\n",
    "    for i in range(len(doc) - 1):\n",
    "        edges[0].append(word_to_idx[doc[i]])\n",
    "        edges[1].append(word_to_idx[doc[i + 1]])\n",
    "\n",
    "edges = torch.tensor([edges[0], edges[1]], dtype=torch.long)\n",
    "\n",
    "edges = edges.sort(dim=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    " - DT: Determiner (e.g., \"the\", \"this\")\n",
    " - VBZ: Verb, 3rd person singular present (e.g., \"is\")\n",
    " - NN: Noun, singular (e.g., \"document\")\n",
    " - JJ: Adjective (e.g., \"first\", \"second\", \"third\")\n",
    " - CC: Coordinating conjunction (e.g., \"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0,\n",
       " 'the': 1,\n",
       " 'is': 2,\n",
       " 'this': 3,\n",
       " 'first': 4,\n",
       " 'one': 5,\n",
       " 'third': 6,\n",
       " 'and': 7,\n",
       " 'second': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels (example)\n",
    "label_to_id = {\n",
    "    \"DT\": 0, \"JJ\": 1, \"CC\": 2, \"NN\": 3, \"VBZ\": 4,\n",
    "}\n",
    "labels = [0, 1, 2, 1, 0, 3, 4, 3, 1]  # Example labels for nodes\n",
    "labels = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the PyTorch Geometric Data object\n",
    "data = Data(x=embeddings, edge_index=edges, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[9, 9], edge_index=[2, 18], y=[9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# GraphSAGE Model Definition\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        # Define two layers of SAGEConv\n",
    "        self.conv1 = SAGEConv(in_channels, 16)\n",
    "        self.conv2 = SAGEConv(16, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Apply the first GraphSAGE layer (with ReLU activation)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # Apply the second GraphSAGE layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = data.x.size(1)  \n",
    "out_channels = len(label_to_id)  \n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Create the model\n",
    "model = GraphSAGE(in_channels, out_channels)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out[data.y != -1], data.y[data.y != -1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)  # Predicted labels are the ones with the highest score\n",
    "    correct = (pred == data.y).sum().item()\n",
    "    accuracy = correct / data.num_nodes\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
