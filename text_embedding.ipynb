{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embeddings\n",
    "\n",
    " - text does not have a inherit semantic distance between words. (hamming-distance...)\n",
    " - Given the text: \"This is the first document\" and \"Is this the first document?\", how similar are these? \n",
    " - Transform text (Graph) into vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-Of-Words \n",
    " - Idea: Create Vocabulary Array of size x, containing every word\n",
    " - For each document ys: count how often each word occurs\n",
    " - x*y matrix containing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer counts occurences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectoricer : CountVectorizer = CountVectorizer()\n",
    "bow_embedding = bow_vectoricer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns the Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectoricer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_embedding.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_embeddings = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_embeddings.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    " - Get Cooccurance of words in the document. \n",
    " - The higher the cooccurance between two words, the more similar the vectors should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    " - We want the embeddings of the words\n",
    " - Thus we need to split the sentences into the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[word for word in document.split(\" \")] for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'the', 'first', 'document.'],\n",
       " ['This', 'document', 'is', 'the', 'second', 'document.'],\n",
       " ['And', 'this', 'is', 'the', 'third', 'one.'],\n",
       " ['Is', 'this', 'the', 'first', 'document?']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=tokens, vector_size=9, window=2, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedding = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([word for line in tokens for word in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third: [ 0.03140464  0.0599922   0.07838441 -0.06337231  0.02067937  0.06765798\n",
      " -0.05332528 -0.03455647  0.07553378]\n",
      "This: [-0.0032909  -0.08512489  0.10683048  0.0553562   0.10259048 -0.09064353\n",
      "  0.04995332 -0.04596751  0.00916151]\n",
      "document: [-0.03155611 -0.06859469 -0.00455803 -0.09298832 -0.06222236  0.07893932\n",
      "  0.03725044  0.08028522  0.0755583 ]\n",
      "second: [ 0.07102815 -0.09577431  0.04073042  0.05766537  0.06379931  0.08296576\n",
      " -0.06852973  0.0122846   0.06719203]\n",
      "one.: [-0.01615424 -0.10232265  0.04856641  0.00635378  0.08269591 -0.00903735\n",
      " -0.02931856 -0.09726511 -0.00951822]\n",
      "Is: [-0.08536667 -0.01677566  0.02745128 -0.00986536  0.06150129 -0.03047973\n",
      "  0.02510632  0.06060106  0.09273084]\n",
      "the: [-0.00595808  0.00262702  0.05670388  0.10010304 -0.10336611 -0.07907566\n",
      "  0.07176525  0.09969987 -0.05572698]\n",
      "document?: [ 0.09443673 -0.04957192  0.05022183 -0.07542852 -0.03941385  0.10444671\n",
      " -0.01754775  0.00355158 -0.04598591]\n",
      "And: [ 0.01812751  0.00211019  0.03859597  0.00241975  0.10687584  0.05622893\n",
      " -0.09908211 -0.07823956  0.01001618]\n",
      "first: [ 0.0897493  -0.06589884  0.0005018  -0.05281927 -0.10670611  0.05563659\n",
      " -0.09732873 -0.04879806 -0.00039   ]\n",
      "document.: [ 0.06409526 -0.08357375 -0.04373448 -0.08346203 -0.0103338   0.1059791\n",
      " -0.08132407 -0.02593076 -0.02153046]\n",
      "is: [-0.04181524  0.08200561 -0.01703857 -0.05040681  0.07282279 -0.05400178\n",
      " -0.02017797  0.031962    0.01102082]\n",
      "this: [-0.09205794 -0.10498687  0.08124185  0.05633624  0.07508548  0.00847628\n",
      "  0.07056545 -0.0378374  -0.01051557]\n"
     ]
    }
   ],
   "source": [
    "for word in vocab:\n",
    "    if(word in word2vec.wv):\n",
    "        print(f\"{word}: {w2v_embedding[word]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justinmucke/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(corpus, return_tensors=\"pt\", padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1996, 2034, 6254, 1012,  102,    0],\n",
       "        [ 101, 2023, 6254, 2003, 1996, 2117, 6254, 1012,  102],\n",
       "        [ 101, 1998, 2023, 2003, 1996, 2353, 2028, 1012,  102],\n",
       "        [ 101, 2003, 2023, 1996, 2034, 6254, 1029,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**input)\n",
    "word_embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding of the first word in the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7925e-01,  2.4680e-01,  2.5877e-01, -1.9693e-01, -2.1139e-01,\n",
      "        -5.1831e-01,  5.0253e-02,  2.8839e-01,  1.1750e-02, -2.5680e-01,\n",
      "        -1.9406e-01, -1.9011e-01,  1.1257e-01,  2.8728e-01,  1.0411e-01,\n",
      "        -4.6118e-02, -2.3991e-01,  4.7052e-01,  2.7609e-01, -3.5730e-01,\n",
      "        -2.3314e-01, -4.6894e-01, -6.8953e-02, -2.2837e-01, -2.8003e-01,\n",
      "        -5.4488e-02, -4.0301e-02,  7.6617e-02, -2.5184e-01,  4.3663e-02,\n",
      "         1.3813e-01,  2.9083e-02, -6.6083e-02,  3.3753e-01,  2.7510e-01,\n",
      "         1.3768e-01,  1.2088e-01, -7.7740e-02,  2.3999e-01, -3.1664e-02,\n",
      "         1.0138e-01,  8.5622e-02,  6.9635e-02, -2.0513e-01,  1.4577e-01,\n",
      "        -4.3383e-01, -2.5102e+00, -1.3555e-01, -6.0130e-02, -8.5688e-02,\n",
      "         6.8202e-02, -3.6489e-01,  6.4345e-02,  2.8158e-01, -9.2559e-02,\n",
      "         2.7825e-01, -4.3326e-01,  5.4751e-01, -8.6024e-02,  2.6318e-01,\n",
      "         1.5872e-01, -1.7574e-01,  1.9737e-01,  1.1068e-02,  3.8963e-02,\n",
      "         8.8484e-02, -1.6272e-01,  1.3865e-02, -3.9311e-02,  5.4802e-01,\n",
      "        -5.0963e-01, -1.6215e-01,  3.5540e-01, -2.3589e-01,  8.7557e-02,\n",
      "        -2.2572e-01, -1.2603e-01,  2.1547e-01, -7.6883e-02, -8.1878e-02,\n",
      "         7.1167e-02,  5.4295e-01,  1.2307e-01, -8.7966e-03,  1.0441e-01,\n",
      "         3.8880e-01, -5.2223e-01, -4.7387e-01,  3.1792e-01,  3.6230e-01,\n",
      "        -2.1718e-01,  2.5355e-01,  1.7125e-02,  3.5323e-01,  1.3344e-01,\n",
      "        -3.9075e-01, -2.1118e-01,  1.9484e-01,  3.3063e-01,  2.6241e-01,\n",
      "         4.0335e-01,  8.5141e-02,  1.1538e-01, -4.8537e-01, -8.1966e-02,\n",
      "        -2.9537e-01, -2.0787e-01, -1.1109e-01,  2.9929e-01, -2.7678e+00,\n",
      "         7.1600e-01,  4.0039e-02, -1.9441e-01,  3.6666e-02, -2.6382e-01,\n",
      "         6.4691e-01,  4.2749e-01, -3.2229e-01,  2.2607e-01,  9.5786e-02,\n",
      "        -2.9567e-01,  5.1900e-01, -2.5313e-01, -2.8420e-01, -1.4778e-01,\n",
      "         4.8524e-01,  2.2675e-01,  2.7577e-01,  1.8758e-01,  3.9335e-02,\n",
      "        -4.2523e-02,  4.9043e-01,  1.5912e-01, -1.9852e-01,  2.1476e-01,\n",
      "         1.1027e-01,  1.1826e-01, -9.0479e-03, -2.4215e-01, -1.1888e-01,\n",
      "        -2.7024e-01, -1.9784e-01, -2.8764e+00,  2.6332e-01,  5.2999e-01,\n",
      "         3.8085e-01, -3.6709e-01, -1.1104e-01,  1.1758e-01,  1.3972e-01,\n",
      "         5.5929e-02,  7.2917e-02, -4.9773e-02,  1.4143e-01, -2.4859e-01,\n",
      "        -1.2814e-01,  3.6466e-02,  9.5989e-02,  3.1754e-01,  5.5010e-01,\n",
      "         2.5475e-01, -7.7536e-02,  3.0052e-01,  1.0995e-01, -3.8510e-01,\n",
      "         2.9840e-01,  4.2866e-01, -8.3217e-02,  4.2161e-01,  5.8887e-02,\n",
      "        -1.7195e-01, -1.4394e-02,  1.8254e-02,  3.5506e-02, -5.8793e-02,\n",
      "        -1.9346e-01,  2.2548e-01,  3.1680e-01,  1.8233e-01, -1.7126e-01,\n",
      "        -2.9144e-01,  2.3475e-01, -1.9130e-01,  9.1683e-02,  2.4028e-01,\n",
      "         2.2023e-03,  4.3463e-01,  2.3442e-01, -2.0114e-01,  2.0986e-01,\n",
      "         9.2738e-03, -2.7947e-01,  8.1991e-02,  4.3300e-02,  3.1119e-01,\n",
      "         1.1744e-02,  4.5355e-01, -3.6893e-01, -4.0183e-02,  4.4500e-01,\n",
      "        -1.3400e-01,  5.4831e-02, -1.3608e-01, -4.9100e-02,  8.7221e-02,\n",
      "         3.8168e+00,  1.4073e-02, -2.5377e-01,  2.2806e-01,  9.5498e-02,\n",
      "        -3.3151e-01,  4.4203e-01,  8.4579e-03, -1.6976e-01,  4.1991e-01,\n",
      "         2.8976e-02,  4.6489e-01, -6.5826e-02, -2.1599e-01, -1.5212e-01,\n",
      "         7.4248e-02,  2.4556e-01,  3.3502e-02,  3.5343e-01, -1.7669e-01,\n",
      "        -1.4071e-01, -8.0737e-02,  6.0835e-01, -4.8038e-02, -1.5181e+00,\n",
      "         8.8834e-02, -3.4332e-02, -7.1172e-02,  4.6847e-01, -1.0004e-03,\n",
      "        -1.7140e-01, -2.0289e-01, -1.1568e-01,  2.3231e-01,  1.4787e-01,\n",
      "         3.5600e-01,  4.0010e-01, -1.6666e-01,  7.6597e-02, -4.2974e-01,\n",
      "         2.7790e-01,  3.6576e-01, -1.6457e-01,  9.9333e-02, -3.6421e-01,\n",
      "         5.4703e-01, -2.9329e-01, -8.0929e-02, -2.1103e-01, -1.1515e-01,\n",
      "         6.3094e-02,  2.0834e-01,  1.0108e-01, -4.0198e-01,  1.1967e-01,\n",
      "        -4.1805e-01, -2.2445e-01,  1.5362e-01,  1.2940e-01, -5.1718e-01,\n",
      "        -1.1021e-01,  1.8085e-01, -2.5939e-01,  8.0380e-02, -1.8168e-01,\n",
      "        -7.8310e-02, -1.4728e-01, -3.3011e-01, -3.8314e+00,  2.4532e-01,\n",
      "         2.1971e-01,  4.7158e-01,  1.7577e-01, -8.9032e-02,  1.1502e-01,\n",
      "         1.9105e-01, -4.6183e-02, -3.0211e-01,  6.8099e-01,  2.5683e-01,\n",
      "        -2.5208e-01,  4.4595e-01, -4.7442e-01,  1.9858e-01, -2.6785e-02,\n",
      "        -8.5436e-02, -3.2048e-02, -3.2606e-01, -3.9605e-02,  2.7183e-01,\n",
      "        -2.1532e-01,  6.2858e-02,  1.4592e-02, -1.1933e-01, -2.2516e-01,\n",
      "        -3.2283e-01,  2.5802e-01, -8.8304e-02, -9.2233e-02, -1.5700e-01,\n",
      "         5.7496e-02, -7.8317e-02,  1.0920e-01, -3.4716e+00,  4.7551e-03,\n",
      "        -4.0959e-01, -1.2037e-01, -2.3901e-02, -2.9350e-01,  6.3209e-01,\n",
      "        -2.1519e-02, -4.3216e-02,  5.0520e-02, -7.7922e-02, -4.6248e-02,\n",
      "        -2.0553e-02,  3.6509e-01,  3.8293e-01,  3.5688e-01,  3.2628e-01,\n",
      "         2.8743e-01,  2.4765e-01,  3.5432e-01, -1.2912e-01, -1.1422e-01,\n",
      "         5.7523e-02, -2.8086e-01,  3.8343e-01,  3.1252e-01, -4.7843e-01,\n",
      "         6.2616e-02, -1.9096e-01,  1.2685e-01,  1.2421e-01,  1.7024e-02,\n",
      "         1.9389e-03, -2.7385e-01, -6.8485e-01, -2.6149e-01,  1.5964e-01,\n",
      "         4.4342e-01,  3.2015e-01, -1.6691e-01, -1.1158e-01,  4.3315e-01,\n",
      "        -3.5067e-02,  4.1695e-01,  2.3760e-01,  2.5050e-01, -4.7479e-02,\n",
      "        -2.1527e-01,  1.1156e-02,  2.2093e-01, -4.3763e-01, -1.5429e-01,\n",
      "         9.0038e-01, -1.6219e-01, -1.2213e-01, -1.3252e-01,  2.4678e-01,\n",
      "         2.7246e-02,  1.3595e-02,  3.7437e-01,  4.0892e-01, -3.4005e-01,\n",
      "         1.9456e-01, -2.1381e-01,  1.0427e-01, -2.9976e-01,  3.2282e-01,\n",
      "        -2.6686e-01,  4.7193e-02,  5.9978e-02,  4.5913e-02,  1.2600e-01,\n",
      "        -4.6139e-01, -1.0363e+00, -1.8323e-01,  2.7655e-02, -6.8253e-02,\n",
      "         3.4109e-01,  1.3484e-01,  6.7826e-02, -2.7774e-02, -5.4396e-02,\n",
      "        -2.2654e-01,  7.0876e-01, -2.6028e-04, -2.6296e-02,  3.9104e-01,\n",
      "        -1.1136e-02, -3.6599e-01, -1.1992e-01, -2.9244e-01,  1.7539e-01,\n",
      "         3.2508e-02,  1.5119e-01, -1.5073e-01, -1.6213e-01,  2.2755e-01,\n",
      "        -8.8531e-01,  4.8240e-02, -2.2357e-01,  5.2084e-02, -3.0719e-01,\n",
      "        -1.4603e-01,  2.3956e-01, -2.1690e-01, -1.7833e-01, -1.4286e-01,\n",
      "         3.1141e-01,  2.8771e-03,  5.9243e-01, -1.4720e-01, -1.9740e-01,\n",
      "         1.7885e-01, -1.4309e-01,  7.3457e-01, -2.9661e-02, -2.0995e-01,\n",
      "         2.3181e-01, -2.8306e-02,  2.0381e-01,  4.3751e-01, -8.1447e-02,\n",
      "         2.4389e-02, -4.2860e-03, -5.2401e-01,  1.8002e-01,  8.6713e-02,\n",
      "        -3.2589e-01, -2.9429e-01, -2.4255e-01, -1.0271e-01, -1.3964e-01,\n",
      "        -3.0365e-01, -7.1902e-01,  1.7510e-01, -1.2905e-01, -2.9402e-01,\n",
      "         2.4514e-01,  2.0849e-01, -2.3370e-01,  2.7583e-01, -1.3785e-01,\n",
      "        -4.3374e-01,  1.2802e-01, -1.3191e-01,  3.3026e-01, -5.0971e-03,\n",
      "        -2.1264e-02, -3.0894e-01,  3.9088e-01,  2.3759e-01, -3.0425e-01,\n",
      "        -7.9547e-02,  9.8019e-02, -1.1762e-01, -1.6755e-02,  4.7767e-03,\n",
      "        -6.8908e-02,  1.1085e-01,  3.3343e-01, -3.1848e-01,  2.4754e-01,\n",
      "        -1.2273e+00,  2.2641e-01,  5.1263e-01,  2.6250e-02,  1.5070e-02,\n",
      "        -2.0239e-02, -5.5214e-01,  5.9601e-01, -8.9015e-02,  2.3059e-01,\n",
      "        -4.3970e-01, -2.1282e-01,  3.6768e-01, -6.3129e-02, -1.7865e-02,\n",
      "         2.4400e-01,  2.4807e-01, -3.0486e-01,  2.0050e-02, -8.1871e-02,\n",
      "        -2.2779e-01,  4.1412e-01, -2.0516e-01,  1.0324e-01,  1.7984e-01,\n",
      "        -2.1517e-01, -6.6216e-02,  3.6218e-01,  1.7002e-02,  1.1558e-01,\n",
      "         1.3126e-01, -3.8050e-01, -4.6007e-01, -2.6918e-01,  1.2069e-01,\n",
      "         5.4738e-02,  3.0407e-01, -2.2448e-01,  3.9101e-01,  5.6030e-01,\n",
      "        -1.1035e-01,  5.4609e-01,  1.2278e-01, -5.7483e-02,  3.5272e-01,\n",
      "         2.8913e-01, -4.1532e-01,  1.1893e-01,  2.1367e-01, -3.9371e-01,\n",
      "        -1.6884e-01, -1.1433e-01, -3.8924e-01, -3.4547e-01,  2.6592e-01,\n",
      "        -6.6245e-02,  1.5337e-01,  4.2627e-03, -1.9459e-01, -1.6141e-02,\n",
      "         2.9070e-01, -3.3827e-01, -4.4566e-02,  2.3386e-01, -2.1328e-01,\n",
      "        -5.3403e-01,  3.2159e-01, -3.0545e-01,  2.0622e-03,  2.7085e-01,\n",
      "         5.0513e-01, -1.5207e-01, -4.2801e-01, -8.4387e-02, -6.8926e-01,\n",
      "         2.1713e-01,  6.2291e-02,  3.1779e-01,  1.6892e-01, -7.1951e-02,\n",
      "         2.3473e-01, -7.4322e-01, -4.7341e-01,  1.3380e-01,  4.2775e-02,\n",
      "         1.7179e-01, -1.6389e-01,  1.0952e-01, -1.6519e-01, -5.4619e-02,\n",
      "        -4.5813e-01, -2.9278e-01,  4.5489e-01,  3.1117e-01,  2.0715e-01,\n",
      "         2.8591e-01, -1.5751e-02, -1.2360e-01,  1.9753e-01, -1.1754e-01,\n",
      "         1.1053e-02,  3.1154e-01,  3.9585e-01,  3.9688e-01, -7.8328e-02,\n",
      "         3.2745e-01,  3.5168e-01,  2.8060e-01, -3.2400e-01, -3.1279e-01,\n",
      "        -2.3612e-01, -1.3714e-01, -4.9611e-02, -1.3647e-01,  2.0525e-01,\n",
      "         1.1851e-01,  1.1381e-01, -5.1051e-02,  2.1451e+00,  5.3828e-01,\n",
      "         5.9305e-02,  2.6965e-02,  1.5568e-01,  8.3180e-02, -2.9467e-01,\n",
      "         3.6196e-01, -1.3149e-01,  3.5965e-01, -2.2142e-01, -6.6749e-03,\n",
      "        -2.0309e-01,  3.7350e-01,  3.1501e-01,  1.7109e-01, -5.9737e-02,\n",
      "        -2.6755e-01, -6.0984e-01, -4.9286e-02, -3.8950e-01,  7.5352e-01,\n",
      "         2.0201e-01, -1.8714e-01,  1.3986e-01,  4.5267e-01,  8.6383e-02,\n",
      "         2.5802e-01,  2.7995e-03,  4.3989e-01,  1.9151e-01,  1.3807e-01,\n",
      "         6.8555e-02,  1.5996e-01, -4.1806e-01, -8.5443e-02, -4.4336e-02,\n",
      "        -1.3873e-01, -2.8440e-01, -6.7563e-02, -4.0183e-02, -3.1352e-01,\n",
      "         2.2821e-01, -1.5190e-01, -3.8478e-01,  5.2220e-01, -2.4234e-01,\n",
      "        -2.3140e-01,  1.5841e-01,  9.9042e-02,  1.6737e-01,  5.8865e-02,\n",
      "        -3.6684e-02,  9.9178e-02, -4.6212e-01, -3.8185e-01,  1.0523e-01,\n",
      "        -2.3333e-01,  1.2900e-02,  5.7677e-01,  1.4569e-01,  3.6312e-01,\n",
      "         7.3422e-02, -3.0823e-01,  1.5005e-02, -2.7271e-01, -4.8881e-01,\n",
      "         3.4475e-01,  1.2218e-01, -9.0948e-02, -4.3310e-02,  2.2840e-01,\n",
      "         4.4584e-01,  3.3158e-01,  1.9464e-01,  4.5913e-02,  8.6727e-02,\n",
      "        -3.7259e-02, -1.5467e-01, -3.1029e+00,  1.0563e-01,  1.6904e-01,\n",
      "         1.1113e-01,  4.7052e-01,  2.8481e-01,  2.3773e-01,  1.8108e-01,\n",
      "         2.6150e-01,  1.6060e-01,  3.1324e-01,  3.7559e-01,  1.8163e-01,\n",
      "         1.0506e-01,  2.4818e-01,  2.4094e-02,  3.2472e-02, -1.7417e-01,\n",
      "        -1.8743e-01, -5.2769e-02, -1.4749e-01,  9.5310e-03,  4.4525e-02,\n",
      "        -7.2480e-02, -5.9273e-01, -1.2425e-01,  7.1656e-02, -1.8412e-01,\n",
      "         1.8728e-01,  3.7205e-01, -2.3088e-01,  1.3285e-01, -2.0868e-01,\n",
      "         2.6447e-01, -1.3583e-01, -3.4655e-01, -6.4327e-05,  9.5351e-02,\n",
      "         4.5834e-01,  1.7375e-01, -1.4207e-01,  3.3311e-01, -2.7386e-01,\n",
      "         3.6196e-01, -3.6535e-01,  5.1254e-02,  1.8317e-01, -2.5296e-01,\n",
      "         1.8116e-01, -1.5823e-01, -1.3965e-01,  2.5644e-01,  5.7147e-02,\n",
      "         1.8362e-01,  5.2983e-01,  1.1477e-01,  1.9275e-01, -1.7589e-01,\n",
      "        -3.8519e-02, -8.7588e-02, -9.5183e-02, -2.3036e-01,  3.5522e-02,\n",
      "        -8.5508e-02,  6.4008e-01, -2.5773e-01, -2.1240e-01,  1.2758e-01,\n",
      "         2.4468e-02, -5.2285e-03, -2.9361e-01,  1.7320e-01,  1.3513e-01,\n",
      "         4.6871e-01, -1.0118e-01, -7.3819e-02,  3.0139e-01, -3.7327e-02,\n",
      "         2.9677e-01, -3.9994e-02, -1.5972e-01, -4.8884e-01, -1.7506e-01,\n",
      "         9.3389e-02,  2.2526e-01, -7.6284e+00, -2.4494e-01, -2.2257e-01,\n",
      "        -3.4133e-01, -1.5592e-01,  1.9385e-01,  1.0052e-01,  1.1790e-02,\n",
      "         1.3487e-01, -1.7255e-02, -8.1190e-02,  1.6152e-01, -5.9223e-02,\n",
      "        -3.1446e-01,  4.1729e-01,  4.5255e-01])\n"
     ]
    }
   ],
   "source": [
    "print(word_embeddings[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
